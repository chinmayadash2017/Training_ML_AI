{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The goal of this assignment is to understand precision-recall in the context of classifiers.\n",
    "\n",
    "Use Amazon review data in its entirety.\n",
    "Train a logistic regression model.\n",
    "Explore various evaluation metrics: accuracy, confusion matrix, precision, recall.\n",
    "Explore how various metrics can be combined to produce a cost of making an error.\n",
    "Explore precision and recall curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "products = pd.read_csv(\"amazon_baby.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def remove_punctuation(text):\n",
    "    import string\n",
    "    return text.translate(str.maketrans('','',string.punctuation))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def remove_numbers(text):\n",
    "    return text.translate(str.maketrans('','','0123456789'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def clean_str(string):\n",
    "    \"\"\"\n",
    "    Tokenization/string cleaning for all datasets except for SST.\n",
    "    Original taken from https://github.com/yoonkim/CNN_sentence/blob/master/process_data.py\n",
    "    \"\"\"\n",
    "    import re\n",
    "    string = re.sub(r\"[^A-Za-z0-9(),!?\\'\\`]\", \" \", string)\n",
    "    string = re.sub(r\"\\'s\", \" \\'s\", string)\n",
    "    string = re.sub(r\"\\'ve\", \" \\'ve\", string)\n",
    "    string = re.sub(r\"n\\'t\", \" n\\'t\", string)\n",
    "    string = re.sub(r\"\\'re\", \" \\'re\", string)\n",
    "    string = re.sub(r\"\\'d\", \" \\'d\", string)\n",
    "    string = re.sub(r\"\\'ll\", \" \\'ll\", string)\n",
    "    string = re.sub(r\",\", \" , \", string)\n",
    "    string = re.sub(r\"!\", \" ! \", string)\n",
    "    string = re.sub(r\"\\(\", \" \\( \", string)\n",
    "    string = re.sub(r\"\\)\", \" \\) \", string)\n",
    "    string = re.sub(r\"\\?\", \" \\? \", string)\n",
    "    string = re.sub(r\"\\s{2,}\", \" \", string)\n",
    "    return string.strip().lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "products = products[products[\"rating\"] != 3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "products[\"sentiment\"] = products[\"rating\"].apply(lambda x : 1 if x >=4 else -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "positive review count:  140259\n",
      "negative review count:  26493\n"
     ]
    }
   ],
   "source": [
    "pos = (products[\"sentiment\"]==1).sum()\n",
    "neg = (products[\"sentiment\"]==-1).sum()\n",
    "print(\"positive review count: \", (pos))\n",
    "print(\"negative review count: \" ,(neg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "products[\"word_counts\"] = products[\"review\"].apply(lambda x : len(str(x).split(\" \")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def text_preprocessing(df,col_in,col_out):\n",
    "    from nltk.corpus import stopwords\n",
    "    stop = stopwords.words('english')\n",
    "    from textblob import TextBlob\n",
    "    from nltk.stem import PorterStemmer\n",
    "    st = PorterStemmer()\n",
    "    from textblob import Word\n",
    "    from tqdm import tqdm\n",
    "    \n",
    "    #df is dataframe\n",
    "    # col_in: input column used for processing\n",
    "    # col_out: output column name\n",
    "    # return df\n",
    "    tqdm.pandas(desc=\"lower_case\")\n",
    "    # convert to lower_case\n",
    "    df[col_out] = df[col_in].progress_apply(lambda x : str(x).lower())\n",
    "    print(\"\\n\")\n",
    "    tqdm.pandas(desc=\"Punctuation\")\n",
    "    # Removing Punctuation\n",
    "    df[col_out] = df[col_out].progress_apply(lambda x : remove_punctuation(str(x)))\n",
    "    print(\"\\n\")\n",
    "    tqdm.pandas(desc=\"Stop_Words\")\n",
    "    # Removal of Stop Words\n",
    "    df[col_out] = df[col_out].progress_apply(lambda x : \" \".join([i for i in x.split() if i not in stop]))\n",
    "    #print(\"\\n\")\n",
    "    #tqdm.pandas(desc=\"Spelling_correction\")\n",
    "    # Spelling correction\n",
    "    #df[col_out] = df[col_out].progress_apply(lambda x : str(TextBlob(x).correct()))\n",
    "    print(\"\\n\")\n",
    "    tqdm.pandas(desc=\"Stemming\")\n",
    "    # Stemming: removal of “ing”, “ly”, “s”\n",
    "    df[col_out] = df[col_out].progress_apply(lambda x : \" \".join([st.stem(word) for word in x.split()]))\n",
    "    print(\"\\n\")\n",
    "    tqdm.pandas(desc=\"Lemmatization\")\n",
    "    # Lemmatization\n",
    "    df[col_out] = df[col_out].progress_apply(lambda x: \" \".join([Word(word).lemmatize(\"v\") for word in x.split()]))\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nimport progressbar\\nfrom time import sleep\\nbar = progressbar.ProgressBar(maxval=20,     widgets=[progressbar.Bar(\\'=\\', \\'[\\', \\']\\'), \\' \\', progressbar.Percentage()])\\nbar.start()\\nproducts = text_preprocessing(products, \"review\", \"review_processed\")\\nbar.finish()\\n'"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "import progressbar\n",
    "from time import sleep\n",
    "bar = progressbar.ProgressBar(maxval=20, \\\n",
    "    widgets=[progressbar.Bar('=', '[', ']'), ' ', progressbar.Percentage()])\n",
    "bar.start()\n",
    "products = text_preprocessing(products, \"review\", \"review_processed\")\n",
    "bar.finish()\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "lower_case: 100%|██████████████████████████████████████████████████████████| 166752/166752 [00:01<00:00, 165563.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Punctuation: 100%|██████████████████████████████████████████████████████████| 166752/166752 [00:02<00:00, 65325.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Stop_Words: 100%|████████████████████████████████████████████████████████████| 166752/166752 [00:45<00:00, 3704.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Stemming: 100%|███████████████████████████████████████████████████████████████| 166752/166752 [05:14<00:00, 529.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Lemmatization: 100%|█████████████████████████████████████████████████████████| 166752/166752 [01:30<00:00, 1836.02it/s]\n"
     ]
    }
   ],
   "source": [
    "products = text_preprocessing(products, \"review\", \"review_processed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>review</th>\n",
       "      <th>rating</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>word_counts</th>\n",
       "      <th>review_processed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Planetwise Wipe Pouch</td>\n",
       "      <td>it came early and was not disappointed. i love...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>30</td>\n",
       "      <td>come earli disappoint love planet wise bag wip...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Annas Dream Full Quilt with 2 Shams</td>\n",
       "      <td>Very soft and comfortable and warmer than it l...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>23</td>\n",
       "      <td>soft comfort warmer looksfit full size bed per...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Stop Pacifier Sucking without tears with Thumb...</td>\n",
       "      <td>This is a product well worth the purchase.  I ...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>78</td>\n",
       "      <td>product well worth purchas find anyth els like...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Stop Pacifier Sucking without tears with Thumb...</td>\n",
       "      <td>All of my kids have cried non-stop when I trie...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>79</td>\n",
       "      <td>kid cri nonstop tri ween pacifi find thumbuddi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Stop Pacifier Sucking without tears with Thumb...</td>\n",
       "      <td>When the Binky Fairy came to our house, we did...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>93</td>\n",
       "      <td>binki fairi come hous didnt special gift book ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                name  \\\n",
       "1                              Planetwise Wipe Pouch   \n",
       "2                Annas Dream Full Quilt with 2 Shams   \n",
       "3  Stop Pacifier Sucking without tears with Thumb...   \n",
       "4  Stop Pacifier Sucking without tears with Thumb...   \n",
       "5  Stop Pacifier Sucking without tears with Thumb...   \n",
       "\n",
       "                                              review  rating  sentiment  \\\n",
       "1  it came early and was not disappointed. i love...       5          1   \n",
       "2  Very soft and comfortable and warmer than it l...       5          1   \n",
       "3  This is a product well worth the purchase.  I ...       5          1   \n",
       "4  All of my kids have cried non-stop when I trie...       5          1   \n",
       "5  When the Binky Fairy came to our house, we did...       5          1   \n",
       "\n",
       "   word_counts                                   review_processed  \n",
       "1           30  come earli disappoint love planet wise bag wip...  \n",
       "2           23  soft comfort warmer looksfit full size bed per...  \n",
       "3           78  product well worth purchas find anyth els like...  \n",
       "4           79  kid cri nonstop tri ween pacifi find thumbuddi...  \n",
       "5           93  binki fairi come hous didnt special gift book ...  "
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "products.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open(\"module-9-assignment-train-idx.json\",\"r\") as file:\n",
    "    train_idx = json.load(file)\n",
    "with open(\"module-9-assignment-test-idx.json\",\"r\") as file:\n",
    "    test_idx = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of train: 133416\n",
      "shape of test: 33336\n"
     ]
    }
   ],
   "source": [
    "train_data = products.iloc[train_idx]\n",
    "test_data = products.iloc[test_idx]\n",
    "print(\"shape of train:\", train_data.shape[0])\n",
    "print(\"shape of test:\", test_data.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "vectorizer = CountVectorizer(token_pattern=r'\\b\\w+\\b')\n",
    "     # Use this token pattern to keep single-letter words\n",
    "# First, learn vocabulary from the training data and assign columns to words\n",
    "# Then convert the training data into a sparse matrix\n",
    "train_matrix = vectorizer.fit_transform(train_data['review_processed'])\n",
    "# Second, convert the test data into a sparse matrix, using the same word-column mapping\n",
    "test_matrix = vectorizer.transform(test_data['review_processed'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(133416, 102457)"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(33336, 102457)"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chinm\\AppData\\Local\\conda\\conda\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py:1: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "C:\\Users\\chinm\\AppData\\Local\\conda\\conda\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py:2: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "y_train = train_data[\"sentiment\"].as_matrix()\n",
    "y_test = test_data[\"sentiment\"].as_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(133416,)"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(33336,)"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = LogisticRegression().fit(train_matrix,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chinm\\AppData\\Local\\conda\\conda\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py:2: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.9228761699064075\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "accuracy = accuracy_score(y_true=test_data['sentiment'].as_matrix(), y_pred=model.predict(test_matrix))\n",
    "print (\"Test Accuracy: %s\" % accuracy)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
